{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.misc import imread\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "from tensorflow.contrib.session_bundle import exporter\n",
    "from keras.models import model_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20522\n"
     ]
    }
   ],
   "source": [
    "test_path = 'data/test-jpg-additional/'\n",
    "test_names = []\n",
    "image_size = 256\n",
    "for i in range(20522):\n",
    "    test_names.append('file_' + str(i))\n",
    "print(len(test_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(data_path, indices, image_size):\n",
    "    num_images = 0\n",
    "    dataset = np.ndarray(shape=(len(indices), image_size, image_size, 3),dtype=np.float32)\n",
    "    for i in tqdm(range(len(indices)), total = len(indices)):\n",
    "        image = data_path + indices[i] + '.jpg'\n",
    "        image_data = mpimg.imread(image)[:,:,:3]\n",
    "        #Normalization\n",
    "        image_data = np.multiply(image_data, 1.0/255.0)\n",
    "        dataset[num_images, :, :, :] = image_data\n",
    "        num_images += 1\n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 20522/20522 [06:54<00:00, 49.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (20522, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "x_test = load_image(test_path, test_names, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 17\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_test.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)\n",
    "def accuracy_with_threshold(y_true, y_pred):\n",
    "    threshold = 0.5\n",
    "    y_pred = K.cast(K.greater(y_pred, threshold), K.floatx())\n",
    "    return K.mean(K.equal(y_true, y_pred))\n",
    "\n",
    "def hamming_dist(y_true, y_pred):\n",
    "    threshold = 0.5\n",
    "    y_pred = K.cast(K.greater(y_pred, threshold), K.floatx())\n",
    "    return K.mean(K.sum(K.abs(y_true - y_pred), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('planet1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(x_test, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = (pred >= 0.5).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission1/planet_predict_1_3.csv', 'w') as outfn:\n",
    "    for idx in range(len(test_names)):\n",
    "        s = test_names[idx]\n",
    "        for j in range(num_classes):\n",
    "            s += ', {:.3f}'.format(pred[idx,j])\n",
    "        outfn.write(s)\n",
    "        outfn.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
