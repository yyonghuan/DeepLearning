{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.misc import imread\n",
    "import matplotlib.image as mpimg\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_all_labels(data_path):\n",
    "    raw_labels = []\n",
    "    with open(data_path) as input_labels:\n",
    "        for line in input_labels:\n",
    "            tokens = line.strip().split(',')\n",
    "            raw_labels.append(tokens[1])\n",
    "    return raw_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "raw_labels = load_all_labels('data/train_v2.csv')\n",
    "raw_labels = raw_labels[1:]\n",
    "label_tf = CountVectorizer(binary=True, max_features=20)\n",
    "labels = label_tf.fit_transform(raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<40479x17 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 116205 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of total images:  40479\n",
      "Numbers of training images:  5000\n",
      "Number of test images:  2000\n"
     ]
    }
   ],
   "source": [
    "n_samples = labels.shape[0]\n",
    "indices = np.random.permutation(n_samples)\n",
    "#Number of images for train dataset and test dataset\n",
    "n_train = 5000\n",
    "n_test = 2000\n",
    "# split the train and test \n",
    "#n_test = int(n_samples * 0.1)\n",
    "print(\"Numbers of total images: \", n_samples)\n",
    "print(\"Numbers of training images: \", n_train)\n",
    "print(\"Number of test images: \", n_test)\n",
    "#test = train_img[indices[:n_test]]\n",
    "#train = train_img[indices[n_test:]]\n",
    "test_labels = labels[indices[:n_test]]\n",
    "train_labels = labels[indices[n_test:n_train+n_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(data_path, indices, image_size):\n",
    "    num_images = 0\n",
    "    dataset = np.ndarray(shape=(len(indices), image_size, image_size, 3),dtype=np.float32)\n",
    "    for i in tqdm(range(len(indices)), total = len(indices)):\n",
    "        image = data_path + 'train_' + str(indices[i]) + '.jpg'\n",
    "        image_data = mpimg.imread(image)[:,:,:3]\n",
    "        #Normalization\n",
    "        image_data = np.multiply(image_data, 1.0/255.0)\n",
    "        dataset[num_images, :, :, :] = image_data\n",
    "        num_images += 1\n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/5000 [00:00<01:20, 62.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training images data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:57<00:00, 87.49it/s] \n",
      "  0%|          | 6/2000 [00:00<00:35, 56.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (5000, 256, 256, 3)\n",
      "Loading testing images data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:24<00:00, 81.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (2000, 256, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/train-jpg/\"\n",
    "image_size = 256\n",
    "print(\"Loading training images data...\")\n",
    "train = load_image(data_path, indices[n_test:n_train+n_test], image_size)\n",
    "print(\"Loading testing images data...\")\n",
    "test = load_image(data_path, indices[:n_test], image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 256, 256, 3)\n",
      "(5000, 17)\n",
      "(2000, 256, 256, 3)\n",
      "(2000, 17)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(train_labels.shape)\n",
    "print(test.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00125054630839\n",
      "0.00130528539836\n"
     ]
    }
   ],
   "source": [
    "# Compute KL divergence\n",
    "test_disb = np.sum(test_labels, axis=0)\n",
    "train_disb = np.sum(train_labels, axis=0)\n",
    "test_disb = test_disb / float(np.sum(test_disb))\n",
    "train_disb = train_disb / float(np.sum(train_disb))\n",
    "\n",
    "kl = np.sum(np.multiply(train_disb, (np.log(train_disb) - np.log(test_disb))))\n",
    "print(kl)\n",
    "\n",
    "kl = np.sum(np.multiply(test_disb, (np.log(test_disb) - np.log(train_disb))))\n",
    "print(kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "def get_session(gpu_fraction=0.1):\n",
    "    '''Assume that you have 6GB of GPU memory and want to allocate ~2GB'''\n",
    "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "\n",
    "    if num_threads:\n",
    "        return tf.Session(config=tf.ConfigProto(\n",
    "            gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
    "    else:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "    \n",
    "import keras.backend as K\n",
    "#K.set_session(get_session(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (5000, 256, 256, 3)\n",
      "5000 train samples\n",
      "2000 test samples\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.applications import vgg16\n",
    "from keras.models import Model\n",
    "\n",
    "img_width = 256\n",
    "img_height = 256\n",
    "batch_size = 32\n",
    "num_classes = 17\n",
    "epochs = 5\n",
    "data_augmentation = False\n",
    "\n",
    "x_train = train\n",
    "x_test = test\n",
    "y_train = train_labels.toarray()\n",
    "y_test = test_labels.toarray()\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build the VGG16 network\n",
    "base_model = vgg16.VGG16(weights = None, include_top = False, input_shape = (img_height, img_width, 3))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1024)              33555456  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 17)                17425     \n",
      "=================================================================\n",
      "Total params: 49,337,169\n",
      "Trainable params: 49,337,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(num_classes, activation = 'sigmoid')(x)\n",
    "model = Model(inputs = base_model.input, outputs = x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_with_threshold(y_true, y_pred):\n",
    "    threshold = 0.5\n",
    "    y_pred = K.cast(K.greater(y_pred, threshold), K.floatx())\n",
    "    return K.mean(K.equal(y_true, y_pred))\n",
    "\n",
    "def hamming_dist(y_true, y_pred):\n",
    "    threshold = 0.5\n",
    "    y_pred = K.cast(K.greater(y_pred, threshold), K.floatx())\n",
    "    return K.mean(K.sum(K.abs(y_true - y_pred), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f_score(y_true, y_pred):\n",
    "    threshold = 0.5\n",
    "    y_pred = K.greater(y_pred, threshold)\n",
    "    \n",
    "    y_pred = tf.to_int32(y_pred)\n",
    "    y_true = tf.to_int32(y_true)\n",
    "    like = tf.ones_like(y_true)\n",
    "    \n",
    "    num_retrieves = tf.reduce_sum(y_pred, 1)\n",
    "    \n",
    "    num_relevants = tf.logical_and((tf.equal(y_true,like)),(tf.equal(y_pred,like)))\n",
    "    num_relevants = tf.to_int32(num_relevants)                                \n",
    "    num_relevants = tf.reduce_sum(num_relevants,1)\n",
    "    \n",
    "    total_relevants = tf.reduce_sum(y_true, 1)\n",
    "    \n",
    "    precision = tf.div(tf.to_float(num_relevants), tf.to_float(num_retrieves))\n",
    "    recall = tf.div(tf.to_float(num_relevants), tf.to_float(total_relevants))\n",
    "    beta = 2.\n",
    "    beta_sqr = beta * beta\n",
    "    #f1 = (1 + beta_sqr) * tf.div(tf.multiply(precision,recall),tf.add(beta_sqr * precision, recall))\n",
    "    return tf.reduce_mean(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1536   46  109   50    9 3518  271    8  524  464  333  878 4618 1032   44\n",
      "   24  916]\n",
      "{0: 9.3619791666666661, 1: 312.60869565217394, 2: 131.92660550458714, 3: 287.60000000000002, 4: 1597.7777777777778, 5: 4.0875497441728257, 6: 53.062730627306273, 7: 1797.5, 8: 27.442748091603054, 9: 30.991379310344829, 10: 43.183183183183182, 11: 16.378132118451024, 12: 3.1139021221307925, 13: 13.934108527131784, 14: 326.81818181818181, 15: 599.16666666666663, 16: 15.698689956331878}\n"
     ]
    }
   ],
   "source": [
    "stat = np.array(np.sum(y_train, axis = 0)).flatten()\n",
    "print(stat)\n",
    "scores = [np.sum(stat)/x for x in stat]\n",
    "class_weights = {}\n",
    "for i in range(len(scores)):\n",
    "    class_weights[i] = scores[i] #if scores[i]>1.0 else 1.0\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_weight = np.zeros((y_train.shape[0], num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(num_classes):\n",
    "    sample_weight[i] = scores.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found a sample_weight array for an input with shape (5000, 17). Timestep-wise sample weighting (use of sample_weight_mode=\"temporal\") is restricted to outputs that are at least 3D, i.e. that have a time dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-8345d42248e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not using data augmentation.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n\u001b[0;32m---> 10\u001b[0;31m                      validation_data=(x_test, y_test), sample_weight = sample_weight, shuffle=True)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using real-time data augmentation.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yangyonghuan/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1430\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yangyonghuan/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1314\u001b[0m         sample_weights = [_standardize_weights(ref, sw, cw, mode)\n\u001b[1;32m   1315\u001b[0m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                           in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\u001b[0m\u001b[1;32m   1317\u001b[0m         \u001b[0m_check_array_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m         _check_loss_and_target_compatibility(y,\n",
      "\u001b[0;32m/Users/yangyonghuan/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                                                    self._feed_output_names)\n\u001b[1;32m   1314\u001b[0m         sample_weights = [_standardize_weights(ref, sw, cw, mode)\n\u001b[0;32m-> 1315\u001b[0;31m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m                           in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\u001b[1;32m   1317\u001b[0m         \u001b[0m_check_array_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yangyonghuan/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(y, sample_weight, class_weight, sample_weight_mode)\u001b[0m\n\u001b[1;32m    527\u001b[0m             raise ValueError('Found a sample_weight array for '\n\u001b[1;32m    528\u001b[0m                              \u001b[0;34m'an input with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m                              \u001b[0;34m'Timestep-wise sample weighting (use of '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                              \u001b[0;34m'sample_weight_mode=\"temporal\") is restricted to '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found a sample_weight array for an input with shape (5000, 17). Timestep-wise sample weighting (use of sample_weight_mode=\"temporal\") is restricted to outputs that are at least 3D, i.e. that have a time dimension."
     ]
    }
   ],
   "source": [
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=[accuracy_with_threshold, hamming_dist, f_score], sample_weight_mode=\"temporal\")\n",
    "\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                     validation_data=(x_test, y_test), sample_weight = sample_weight, shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hamming_dist': [1.6729333335876464, 1.3694666667938233, 1.1745333333969117, 1.0909333333969116, 1.0273333333333334, 0.97419999999999995, 0.92593333336512251, 0.87253333346048989, 0.84660000000000002, 0.81073333336512243, 0.77820000006357826, 0.75060000003178917, 0.72219999999999995, 0.6992666666666667, 0.67959999999999998, 0.64793333346048987, 0.61240000001589456, 0.5992000000476837, 0.56513333333333338, 0.54466666668256125, 0.52306666668256119, 0.49986666669845581, 0.4760000000158946, 0.45506666668256124, 0.4396000000635783, 0.4268666666984558, 0.41480000003178913, 0.4011333333412806, 0.3898000000158946, 0.38093333333333335, 0.36793333336512246, 0.36879999993642171, 0.35573333338101704, 0.35093333333730697, 0.33966666668256124, 0.34453333333333336, 0.33046666668256125, 0.3298666666706403, 0.328533333337307, 0.31953333333333334], 'loss': [0.25886614909172057, 0.19879011034965516, 0.17499071365992228, 0.16097121550242105, 0.15200471782286962, 0.14373897492090862, 0.13690229683717092, 0.13100717044671376, 0.12638931973775228, 0.12112595063845316, 0.11564406404495239, 0.11197623000144959, 0.10845847938855489, 0.10413830387194951, 0.10120435413519542, 0.096845480744043991, 0.093266163770357763, 0.089904062199592585, 0.086214534258842471, 0.082653597172101342, 0.079233643698692319, 0.076277593807379404, 0.073318928676843642, 0.069712744800249735, 0.068798437150319414, 0.06760901937882105, 0.065110926580429079, 0.063152776753902434, 0.061145191401243207, 0.060436946068207424, 0.058911886988083521, 0.058083817027012506, 0.057476375436782835, 0.056638405557473501, 0.055472201500336327, 0.056262863167126975, 0.05371070948243141, 0.053852067759633061, 0.052364974683523177, 0.052144273088375728], 'accuracy_with_threshold': [0.90159215974807738, 0.91944314880371092, 0.93090981604258216, 0.93582746766408287, 0.93956864153544106, 0.94269413763682053, 0.94553335447311404, 0.94867453482945763, 0.95020002708435058, 0.95230983209609987, 0.95422355731328323, 0.95584708887736003, 0.95751767778396601, 0.95886670103073124, 0.96002356198628747, 0.96188630720774337, 0.96397650140126545, 0.96475298004150389, 0.96675690021514893, 0.96796082216898605, 0.96923141015370684, 0.97059611616134644, 0.97200003824234005, 0.97323141263326007, 0.97414121303558354, 0.97489023180007939, 0.97560003617604574, 0.97640395997365315, 0.97707062664031985, 0.97759219449361168, 0.97835689830780026, 0.97830591996510818, 0.9790745484987895, 0.97935689738591514, 0.98001964683532716, 0.9797333730061849, 0.980560820388794, 0.98059611803690594, 0.98067454598744708, 0.9812039575576782], 'val_hamming_dist': [1.5805, 1.34775, 1.091, 0.98499999999999999, 0.90849999999999997, 0.88400000000000001, 0.83999999999999997, 0.89775000000000005, 0.83850000000000002, 0.76500000000000001, 0.79849999999999999, 0.78149999999999997, 0.74975000000000003, 0.73650000000000004, 0.76200000000000001, 0.83625000000000005, 0.76324999999999998, 0.78974999999999995, 0.75975000000000004, 0.76675000000000004, 0.76524999999999999, 0.80425000000000002, 0.79725000000000001, 0.92949999999999999, 0.81774999999999998, 0.79725000000000001, 0.75349999999999995, 0.77049999999999996, 0.79274999999999995, 0.81725000000000003, 0.85024999999999995, 0.83875, 0.78649999999999998, 0.77200000000000002, 0.88400000000000001, 0.79300000000000004, 0.84225000000000005, 0.75275000000000003, 0.83150000000000002, 0.78774999999999995], 'val_accuracy_with_threshold': [0.90702942609786985, 0.92072059917449955, 0.93582354497909548, 0.94205885076522822, 0.94655885362625125, 0.94800002431869512, 0.95058826208114622, 0.94719120216369634, 0.95067649650573727, 0.95500002765655523, 0.95302944087982178, 0.95402943897247316, 0.95589709091186525, 0.95667650413513183, 0.95517649745941158, 0.95080885934829706, 0.95510297584533688, 0.95354414796829223, 0.95530885648727415, 0.95489708709716792, 0.95498532056808472, 0.95269120788574224, 0.95310296916961668, 0.94532355499267573, 0.95189708423614505, 0.95310296678543094, 0.95567650175094609, 0.95467650222778322, 0.95336767959594726, 0.95192649030685428, 0.94998532104492184, 0.95066179418563845, 0.95373532485961909, 0.95458827066421503, 0.94800002717971799, 0.95335296630859379, 0.95045591163635257, 0.95572062206268316, 0.95108825969696043, 0.95366179656982419], 'val_loss': [0.21423125183582306, 0.18879292941093445, 0.17047531533241272, 0.15946261727809907, 0.13669557118415832, 0.13308230155706405, 0.12917074000835418, 0.13686952883005143, 0.12799580740928651, 0.11834593236446381, 0.11987095540761948, 0.12286873644590378, 0.1192315309047699, 0.12147356700897217, 0.11825906807184219, 0.12799675369262695, 0.12535569477081299, 0.14579926496744156, 0.13347797000408174, 0.13984425067901612, 0.15299584335088731, 0.147425587952137, 0.1400446054339409, 0.14148554068803787, 0.13317429268360137, 0.15428870737552644, 0.17369197094440461, 0.1772891715168953, 0.18996150738000869, 0.15011176198720932, 0.16547379094362258, 0.15705293774604798, 0.24631542325019837, 0.22445572048425674, 0.2508598985671997, 0.16190020120143891, 0.19537219214439391, 0.22537708747386934, 0.22174292761087416, 0.21719490534067154]}\n"
     ]
    }
   ],
   "source": [
    "print(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('submission/submission2/planet2_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\yyh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\yyh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=0.8955761904761905\n",
      "recall=0.8752970238095238\n",
      "f1=0.8734377576686533\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test, batch_size=batch_size, verbose=0)\n",
    "y_pred = (pred >= 0.5).astype(np.int32)\n",
    "y_pred = y_pred.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "num_relevants = np.sum(y_test & y_pred, axis=1)\n",
    "num_retrieves = np.sum(y_pred, axis=1)\n",
    "total_relevants = np.sum(y_test, axis=1)\n",
    "\n",
    "# precision\n",
    "precision = np.divide(num_relevants.astype(np.float), num_retrieves.astype(np.float))\n",
    "precision = np.nan_to_num(precision)\n",
    "# recall\n",
    "recall = np.divide(num_relevants.astype(np.float), total_relevants.astype(np.float))\n",
    "recall = np.nan_to_num(recall)\n",
    "beta = 2.\n",
    "beta_sqr = beta * beta\n",
    "f1 = (1 + beta_sqr) * np.divide((precision * recall),(beta_sqr * precision + recall))\n",
    "f1 = np.nan_to_num(f1)\n",
    "print('precision={}'.format(np.nanmean(precision)))\n",
    "print('recall={}'.format(np.nanmean(recall)))\n",
    "print('f1={}'.format(np.nanmean(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre = model.predict(x_test,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 17)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21239533,  0.00969336,  0.02384911,  0.05670618,  0.00668827,\n",
       "        0.84235227,  0.01966204,  0.00752299,  0.19295782,  0.08035329,\n",
       "        0.02582694,  0.1628222 ,  0.96848643,  0.14170928,  0.05123476,\n",
       "        0.02263625,  0.18485051], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = K.cast(K.greater(pre, 0.5), K.floatx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Cast_6:0' shape=(1000, 17) dtype=float32>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "y_pred = y_pred.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in range(1000):\n",
    "#    for j in range(17):\n",
    "#        if pre[i][j] >=0.5:\n",
    "#            pre[i][j] = 1\n",
    "#        else:\n",
    "#            pre[i][j]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accracy = K.mean(K.equal(y_test, y_pred)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92405879"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
