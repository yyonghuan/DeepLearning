{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.misc import imread\n",
    "import matplotlib.image as mpimg\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_all_labels(data_path):\n",
    "    raw_labels = []\n",
    "    with open(data_path) as input_labels:\n",
    "        for line in input_labels:\n",
    "            tokens = line.strip().split(',')\n",
    "            raw_labels.append(tokens[1])\n",
    "    return raw_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "raw_labels = load_all_labels('data/train_v2.csv')\n",
    "raw_labels = raw_labels[1:]\n",
    "label_tf = CountVectorizer(binary=True, max_features=20)\n",
    "labels = label_tf.fit_transform(raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<40479x17 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 116205 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of total images:  40479\n",
      "Numbers of training images:  1000\n",
      "Number of test images:  2000\n"
     ]
    }
   ],
   "source": [
    "n_samples = labels.shape[0]\n",
    "indices = np.random.permutation(n_samples)\n",
    "#Number of images for train dataset and test dataset\n",
    "n_train = 1000\n",
    "n_test = 2000\n",
    "# split the train and test \n",
    "#n_test = int(n_samples * 0.3)\n",
    "print(\"Numbers of total images: \", n_samples)\n",
    "print(\"Numbers of training images: \", n_train)\n",
    "print(\"Number of test images: \", n_test)\n",
    "#test = train_img[indices[:n_test]]\n",
    "#train = train_img[indices[n_test:]]\n",
    "test_labels = labels[indices[:n_test]]\n",
    "train_labels = labels[indices[n_test:n_train+n_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_image(data_path, indices, image_size):\n",
    "    num_images = 0\n",
    "    dataset = np.ndarray(shape=(len(indices), image_size, image_size, 3),dtype=np.float32)\n",
    "    for i in tqdm(range(len(indices)), total = len(indices)):\n",
    "        image = data_path + 'train_' + str(indices[i]) + '.jpg'\n",
    "        image_data = mpimg.imread(image)[:,:,:3]\n",
    "        #Normalization\n",
    "        image_data = np.multiply(image_data, 1.0/255.0)\n",
    "        dataset[num_images, :, :, :] = image_data\n",
    "        num_images += 1\n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [00:00<00:41, 23.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training images data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:20<00:00, 49.11it/s]\n",
      "  0%|          | 4/2000 [00:00<00:50, 39.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (1000, 256, 256, 3)\n",
      "Loading testing images data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 61.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (2000, 256, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/train-jpg/\"\n",
    "image_size = 256\n",
    "print(\"Loading training images data...\")\n",
    "train = load_image(data_path, indices[n_test:n_train+n_test], image_size)\n",
    "print(\"Loading testing images data...\")\n",
    "test = load_image(data_path, indices[:n_test], image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 256, 256, 3)\n",
      "(1000, 17)\n",
      "(2000, 256, 256, 3)\n",
      "(2000, 17)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(train_labels.shape)\n",
    "print(test.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00567196858408\n",
      "0.00635753562508\n"
     ]
    }
   ],
   "source": [
    "# Compute KL divergence\n",
    "test_disb = np.sum(test_labels, axis=0)\n",
    "train_disb = np.sum(train_labels, axis=0)\n",
    "test_disb = test_disb / float(np.sum(test_disb))\n",
    "train_disb = train_disb / float(np.sum(train_disb))\n",
    "\n",
    "kl = np.sum(np.multiply(train_disb, (np.log(train_disb) - np.log(test_disb))))\n",
    "print(kl)\n",
    "\n",
    "kl = np.sum(np.multiply(test_disb, (np.log(test_disb) - np.log(train_disb))))\n",
    "print(kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "def get_session(gpu_fraction=0.1):\n",
    "    '''Assume that you have 6GB of GPU memory and want to allocate ~2GB'''\n",
    "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "\n",
    "    if num_threads:\n",
    "        return tf.Session(config=tf.ConfigProto(\n",
    "            gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
    "    else:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "    \n",
    "import keras.backend as K\n",
    "#K.set_session(get_session(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1000, 256, 256, 3)\n",
      "1000 train samples\n",
      "2000 test samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# dimensions of the generated pictures for each filter.\n",
    "img_width = 256\n",
    "img_height = 256\n",
    "batch_size = 32\n",
    "num_classes = 17\n",
    "epochs = 1\n",
    "data_augmentation = False\n",
    "\n",
    "x_train = train\n",
    "x_test = test\n",
    "y_train = train_labels.toarray()\n",
    "y_test = test_labels.toarray()\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from keras.applications import vgg16\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 256, 256, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)               (None, 127, 127, 32)  864         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNor (None, 127, 127, 32)  96          conv2d_95[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_95 (Activation)       (None, 127, 127, 32)  0           batch_normalization_95[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)               (None, 125, 125, 32)  9216        activation_95[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNor (None, 125, 125, 32)  96          conv2d_96[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_96 (Activation)       (None, 125, 125, 32)  0           batch_normalization_96[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)               (None, 125, 125, 64)  18432       activation_96[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNor (None, 125, 125, 64)  192         conv2d_97[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_97 (Activation)       (None, 125, 125, 64)  0           batch_normalization_97[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, 62, 62, 64)    0           activation_97[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)               (None, 62, 62, 80)    5120        max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNor (None, 62, 62, 80)    240         conv2d_98[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_98 (Activation)       (None, 62, 62, 80)    0           batch_normalization_98[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)               (None, 60, 60, 192)   138240      activation_98[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNor (None, 60, 60, 192)   576         conv2d_99[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_99 (Activation)       (None, 60, 60, 192)   0           batch_normalization_99[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)   (None, 29, 29, 192)   0           activation_99[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)              (None, 29, 29, 64)    12288       max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchNo (None, 29, 29, 64)    192         conv2d_103[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_103 (Activation)      (None, 29, 29, 64)    0           batch_normalization_103[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)              (None, 29, 29, 48)    9216        max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)              (None, 29, 29, 96)    55296       activation_103[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchNo (None, 29, 29, 48)    144         conv2d_101[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchNo (None, 29, 29, 96)    288         conv2d_104[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_101 (Activation)      (None, 29, 29, 48)    0           batch_normalization_101[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_104 (Activation)      (None, 29, 29, 96)    0           batch_normalization_104[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePoo (None, 29, 29, 192)   0           max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)              (None, 29, 29, 64)    12288       max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)              (None, 29, 29, 64)    76800       activation_101[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)              (None, 29, 29, 96)    82944       activation_104[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)              (None, 29, 29, 32)    6144        average_pooling2d_10[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchNo (None, 29, 29, 64)    192         conv2d_100[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchNo (None, 29, 29, 64)    192         conv2d_102[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchNo (None, 29, 29, 96)    288         conv2d_105[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchNo (None, 29, 29, 32)    96          conv2d_106[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_100 (Activation)      (None, 29, 29, 64)    0           batch_normalization_100[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_102 (Activation)      (None, 29, 29, 64)    0           batch_normalization_102[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_105 (Activation)      (None, 29, 29, 96)    0           batch_normalization_105[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_106 (Activation)      (None, 29, 29, 32)    0           batch_normalization_106[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)             (None, 29, 29, 256)   0           activation_100[0][0]             \n",
      "                                                                   activation_102[0][0]             \n",
      "                                                                   activation_105[0][0]             \n",
      "                                                                   activation_106[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)              (None, 29, 29, 64)    16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchNo (None, 29, 29, 64)    192         conv2d_110[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_110 (Activation)      (None, 29, 29, 64)    0           batch_normalization_110[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)              (None, 29, 29, 48)    12288       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)              (None, 29, 29, 96)    55296       activation_110[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchNo (None, 29, 29, 48)    144         conv2d_108[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchNo (None, 29, 29, 96)    288         conv2d_111[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_108 (Activation)      (None, 29, 29, 48)    0           batch_normalization_108[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_111 (Activation)      (None, 29, 29, 96)    0           batch_normalization_111[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePoo (None, 29, 29, 256)   0           mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)              (None, 29, 29, 64)    16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)              (None, 29, 29, 64)    76800       activation_108[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)              (None, 29, 29, 96)    82944       activation_111[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)              (None, 29, 29, 64)    16384       average_pooling2d_11[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchNo (None, 29, 29, 64)    192         conv2d_107[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchNo (None, 29, 29, 64)    192         conv2d_109[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchNo (None, 29, 29, 96)    288         conv2d_112[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchNo (None, 29, 29, 64)    192         conv2d_113[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_107 (Activation)      (None, 29, 29, 64)    0           batch_normalization_107[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_109 (Activation)      (None, 29, 29, 64)    0           batch_normalization_109[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_112 (Activation)      (None, 29, 29, 96)    0           batch_normalization_112[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_113 (Activation)      (None, 29, 29, 64)    0           batch_normalization_113[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)             (None, 29, 29, 288)   0           activation_107[0][0]             \n",
      "                                                                   activation_109[0][0]             \n",
      "                                                                   activation_112[0][0]             \n",
      "                                                                   activation_113[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)              (None, 29, 29, 64)    18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchNo (None, 29, 29, 64)    192         conv2d_117[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_117 (Activation)      (None, 29, 29, 64)    0           batch_normalization_117[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)              (None, 29, 29, 48)    13824       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)              (None, 29, 29, 96)    55296       activation_117[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchNo (None, 29, 29, 48)    144         conv2d_115[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchNo (None, 29, 29, 96)    288         conv2d_118[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_115 (Activation)      (None, 29, 29, 48)    0           batch_normalization_115[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_118 (Activation)      (None, 29, 29, 96)    0           batch_normalization_118[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePoo (None, 29, 29, 288)   0           mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)              (None, 29, 29, 64)    18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)              (None, 29, 29, 64)    76800       activation_115[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)              (None, 29, 29, 96)    82944       activation_118[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)              (None, 29, 29, 64)    18432       average_pooling2d_12[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchNo (None, 29, 29, 64)    192         conv2d_114[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchNo (None, 29, 29, 64)    192         conv2d_116[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchNo (None, 29, 29, 96)    288         conv2d_119[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchNo (None, 29, 29, 64)    192         conv2d_120[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_114 (Activation)      (None, 29, 29, 64)    0           batch_normalization_114[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_116 (Activation)      (None, 29, 29, 64)    0           batch_normalization_116[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_119 (Activation)      (None, 29, 29, 96)    0           batch_normalization_119[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_120 (Activation)      (None, 29, 29, 64)    0           batch_normalization_120[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)             (None, 29, 29, 288)   0           activation_114[0][0]             \n",
      "                                                                   activation_116[0][0]             \n",
      "                                                                   activation_119[0][0]             \n",
      "                                                                   activation_120[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)              (None, 29, 29, 64)    18432       mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchNo (None, 29, 29, 64)    192         conv2d_122[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_122 (Activation)      (None, 29, 29, 64)    0           batch_normalization_122[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)              (None, 29, 29, 96)    55296       activation_122[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchNo (None, 29, 29, 96)    288         conv2d_123[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_123 (Activation)      (None, 29, 29, 96)    0           batch_normalization_123[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)              (None, 14, 14, 384)   995328      mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)              (None, 14, 14, 96)    82944       activation_123[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchNo (None, 14, 14, 384)   1152        conv2d_121[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchNo (None, 14, 14, 96)    288         conv2d_124[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_121 (Activation)      (None, 14, 14, 384)   0           batch_normalization_121[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_124 (Activation)      (None, 14, 14, 96)    0           batch_normalization_124[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)   (None, 14, 14, 288)   0           mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)             (None, 14, 14, 768)   0           activation_121[0][0]             \n",
      "                                                                   activation_124[0][0]             \n",
      "                                                                   max_pooling2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)              (None, 14, 14, 128)   98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchNo (None, 14, 14, 128)   384         conv2d_129[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_129 (Activation)      (None, 14, 14, 128)   0           batch_normalization_129[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)              (None, 14, 14, 128)   114688      activation_129[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchNo (None, 14, 14, 128)   384         conv2d_130[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_130 (Activation)      (None, 14, 14, 128)   0           batch_normalization_130[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)              (None, 14, 14, 128)   98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)              (None, 14, 14, 128)   114688      activation_130[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchNo (None, 14, 14, 128)   384         conv2d_126[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchNo (None, 14, 14, 128)   384         conv2d_131[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_126 (Activation)      (None, 14, 14, 128)   0           batch_normalization_126[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_131 (Activation)      (None, 14, 14, 128)   0           batch_normalization_131[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)              (None, 14, 14, 128)   114688      activation_126[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)              (None, 14, 14, 128)   114688      activation_131[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchNo (None, 14, 14, 128)   384         conv2d_127[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchNo (None, 14, 14, 128)   384         conv2d_132[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_127 (Activation)      (None, 14, 14, 128)   0           batch_normalization_127[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_132 (Activation)      (None, 14, 14, 128)   0           batch_normalization_132[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePoo (None, 14, 14, 768)   0           mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)              (None, 14, 14, 192)   147456      mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)              (None, 14, 14, 192)   172032      activation_127[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)              (None, 14, 14, 192)   172032      activation_132[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)              (None, 14, 14, 192)   147456      average_pooling2d_13[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchNo (None, 14, 14, 192)   576         conv2d_125[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchNo (None, 14, 14, 192)   576         conv2d_128[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchNo (None, 14, 14, 192)   576         conv2d_133[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchNo (None, 14, 14, 192)   576         conv2d_134[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_125 (Activation)      (None, 14, 14, 192)   0           batch_normalization_125[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_128 (Activation)      (None, 14, 14, 192)   0           batch_normalization_128[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_133 (Activation)      (None, 14, 14, 192)   0           batch_normalization_133[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_134 (Activation)      (None, 14, 14, 192)   0           batch_normalization_134[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)             (None, 14, 14, 768)   0           activation_125[0][0]             \n",
      "                                                                   activation_128[0][0]             \n",
      "                                                                   activation_133[0][0]             \n",
      "                                                                   activation_134[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)              (None, 14, 14, 160)   122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchNo (None, 14, 14, 160)   480         conv2d_139[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_139 (Activation)      (None, 14, 14, 160)   0           batch_normalization_139[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)              (None, 14, 14, 160)   179200      activation_139[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchNo (None, 14, 14, 160)   480         conv2d_140[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_140 (Activation)      (None, 14, 14, 160)   0           batch_normalization_140[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)              (None, 14, 14, 160)   122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)              (None, 14, 14, 160)   179200      activation_140[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchNo (None, 14, 14, 160)   480         conv2d_136[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchNo (None, 14, 14, 160)   480         conv2d_141[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_136 (Activation)      (None, 14, 14, 160)   0           batch_normalization_136[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_141 (Activation)      (None, 14, 14, 160)   0           batch_normalization_141[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)              (None, 14, 14, 160)   179200      activation_136[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)              (None, 14, 14, 160)   179200      activation_141[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchNo (None, 14, 14, 160)   480         conv2d_137[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchNo (None, 14, 14, 160)   480         conv2d_142[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_137 (Activation)      (None, 14, 14, 160)   0           batch_normalization_137[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_142 (Activation)      (None, 14, 14, 160)   0           batch_normalization_142[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePoo (None, 14, 14, 768)   0           mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)              (None, 14, 14, 192)   147456      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)              (None, 14, 14, 192)   215040      activation_137[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)              (None, 14, 14, 192)   215040      activation_142[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)              (None, 14, 14, 192)   147456      average_pooling2d_14[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchNo (None, 14, 14, 192)   576         conv2d_135[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchNo (None, 14, 14, 192)   576         conv2d_138[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchNo (None, 14, 14, 192)   576         conv2d_143[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchNo (None, 14, 14, 192)   576         conv2d_144[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_135 (Activation)      (None, 14, 14, 192)   0           batch_normalization_135[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_138 (Activation)      (None, 14, 14, 192)   0           batch_normalization_138[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_143 (Activation)      (None, 14, 14, 192)   0           batch_normalization_143[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_144 (Activation)      (None, 14, 14, 192)   0           batch_normalization_144[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)             (None, 14, 14, 768)   0           activation_135[0][0]             \n",
      "                                                                   activation_138[0][0]             \n",
      "                                                                   activation_143[0][0]             \n",
      "                                                                   activation_144[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)              (None, 14, 14, 160)   122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchNo (None, 14, 14, 160)   480         conv2d_149[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_149 (Activation)      (None, 14, 14, 160)   0           batch_normalization_149[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)              (None, 14, 14, 160)   179200      activation_149[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchNo (None, 14, 14, 160)   480         conv2d_150[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_150 (Activation)      (None, 14, 14, 160)   0           batch_normalization_150[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)              (None, 14, 14, 160)   122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)              (None, 14, 14, 160)   179200      activation_150[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchNo (None, 14, 14, 160)   480         conv2d_146[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchNo (None, 14, 14, 160)   480         conv2d_151[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_146 (Activation)      (None, 14, 14, 160)   0           batch_normalization_146[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_151 (Activation)      (None, 14, 14, 160)   0           batch_normalization_151[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)              (None, 14, 14, 160)   179200      activation_146[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)              (None, 14, 14, 160)   179200      activation_151[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchNo (None, 14, 14, 160)   480         conv2d_147[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchNo (None, 14, 14, 160)   480         conv2d_152[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_147 (Activation)      (None, 14, 14, 160)   0           batch_normalization_147[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_152 (Activation)      (None, 14, 14, 160)   0           batch_normalization_152[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePoo (None, 14, 14, 768)   0           mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)              (None, 14, 14, 192)   147456      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)              (None, 14, 14, 192)   215040      activation_147[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)              (None, 14, 14, 192)   215040      activation_152[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)              (None, 14, 14, 192)   147456      average_pooling2d_15[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchNo (None, 14, 14, 192)   576         conv2d_145[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchNo (None, 14, 14, 192)   576         conv2d_148[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchNo (None, 14, 14, 192)   576         conv2d_153[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchNo (None, 14, 14, 192)   576         conv2d_154[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_145 (Activation)      (None, 14, 14, 192)   0           batch_normalization_145[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_148 (Activation)      (None, 14, 14, 192)   0           batch_normalization_148[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_153 (Activation)      (None, 14, 14, 192)   0           batch_normalization_153[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_154 (Activation)      (None, 14, 14, 192)   0           batch_normalization_154[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)             (None, 14, 14, 768)   0           activation_145[0][0]             \n",
      "                                                                   activation_148[0][0]             \n",
      "                                                                   activation_153[0][0]             \n",
      "                                                                   activation_154[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)              (None, 14, 14, 192)   147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchNo (None, 14, 14, 192)   576         conv2d_159[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_159 (Activation)      (None, 14, 14, 192)   0           batch_normalization_159[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)              (None, 14, 14, 192)   258048      activation_159[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchNo (None, 14, 14, 192)   576         conv2d_160[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_160 (Activation)      (None, 14, 14, 192)   0           batch_normalization_160[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)              (None, 14, 14, 192)   147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)              (None, 14, 14, 192)   258048      activation_160[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchNo (None, 14, 14, 192)   576         conv2d_156[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchNo (None, 14, 14, 192)   576         conv2d_161[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_156 (Activation)      (None, 14, 14, 192)   0           batch_normalization_156[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_161 (Activation)      (None, 14, 14, 192)   0           batch_normalization_161[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)              (None, 14, 14, 192)   258048      activation_156[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)              (None, 14, 14, 192)   258048      activation_161[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchNo (None, 14, 14, 192)   576         conv2d_157[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchNo (None, 14, 14, 192)   576         conv2d_162[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_157 (Activation)      (None, 14, 14, 192)   0           batch_normalization_157[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_162 (Activation)      (None, 14, 14, 192)   0           batch_normalization_162[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePoo (None, 14, 14, 768)   0           mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)              (None, 14, 14, 192)   147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)              (None, 14, 14, 192)   258048      activation_157[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)              (None, 14, 14, 192)   258048      activation_162[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)              (None, 14, 14, 192)   147456      average_pooling2d_16[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchNo (None, 14, 14, 192)   576         conv2d_155[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchNo (None, 14, 14, 192)   576         conv2d_158[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchNo (None, 14, 14, 192)   576         conv2d_163[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchNo (None, 14, 14, 192)   576         conv2d_164[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_155 (Activation)      (None, 14, 14, 192)   0           batch_normalization_155[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_158 (Activation)      (None, 14, 14, 192)   0           batch_normalization_158[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_163 (Activation)      (None, 14, 14, 192)   0           batch_normalization_163[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_164 (Activation)      (None, 14, 14, 192)   0           batch_normalization_164[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)             (None, 14, 14, 768)   0           activation_155[0][0]             \n",
      "                                                                   activation_158[0][0]             \n",
      "                                                                   activation_163[0][0]             \n",
      "                                                                   activation_164[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)              (None, 14, 14, 192)   147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchNo (None, 14, 14, 192)   576         conv2d_167[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_167 (Activation)      (None, 14, 14, 192)   0           batch_normalization_167[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)              (None, 14, 14, 192)   258048      activation_167[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchNo (None, 14, 14, 192)   576         conv2d_168[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_168 (Activation)      (None, 14, 14, 192)   0           batch_normalization_168[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)              (None, 14, 14, 192)   147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)              (None, 14, 14, 192)   258048      activation_168[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchNo (None, 14, 14, 192)   576         conv2d_165[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchNo (None, 14, 14, 192)   576         conv2d_169[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_165 (Activation)      (None, 14, 14, 192)   0           batch_normalization_165[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_169 (Activation)      (None, 14, 14, 192)   0           batch_normalization_169[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)              (None, 6, 6, 320)     552960      activation_165[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)              (None, 6, 6, 192)     331776      activation_169[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchNo (None, 6, 6, 320)     960         conv2d_166[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchNo (None, 6, 6, 192)     576         conv2d_170[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_166 (Activation)      (None, 6, 6, 320)     0           batch_normalization_166[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_170 (Activation)      (None, 6, 6, 192)     0           batch_normalization_170[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)   (None, 6, 6, 768)     0           mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)             (None, 6, 6, 1280)    0           activation_166[0][0]             \n",
      "                                                                   activation_170[0][0]             \n",
      "                                                                   max_pooling2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)              (None, 6, 6, 448)     573440      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchNo (None, 6, 6, 448)     1344        conv2d_175[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_175 (Activation)      (None, 6, 6, 448)     0           batch_normalization_175[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)              (None, 6, 6, 384)     491520      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)              (None, 6, 6, 384)     1548288     activation_175[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchNo (None, 6, 6, 384)     1152        conv2d_172[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchNo (None, 6, 6, 384)     1152        conv2d_176[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_172 (Activation)      (None, 6, 6, 384)     0           batch_normalization_172[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_176 (Activation)      (None, 6, 6, 384)     0           batch_normalization_176[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)              (None, 6, 6, 384)     442368      activation_172[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)              (None, 6, 6, 384)     442368      activation_172[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)              (None, 6, 6, 384)     442368      activation_176[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)              (None, 6, 6, 384)     442368      activation_176[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePoo (None, 6, 6, 1280)    0           mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)              (None, 6, 6, 320)     409600      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchNo (None, 6, 6, 384)     1152        conv2d_173[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchNo (None, 6, 6, 384)     1152        conv2d_174[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchNo (None, 6, 6, 384)     1152        conv2d_177[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchNo (None, 6, 6, 384)     1152        conv2d_178[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)              (None, 6, 6, 192)     245760      average_pooling2d_17[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchNo (None, 6, 6, 320)     960         conv2d_171[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_173 (Activation)      (None, 6, 6, 384)     0           batch_normalization_173[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_174 (Activation)      (None, 6, 6, 384)     0           batch_normalization_174[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_177 (Activation)      (None, 6, 6, 384)     0           batch_normalization_177[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_178 (Activation)      (None, 6, 6, 384)     0           batch_normalization_178[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchNo (None, 6, 6, 192)     576         conv2d_179[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_171 (Activation)      (None, 6, 6, 320)     0           batch_normalization_171[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)           (None, 6, 6, 768)     0           activation_173[0][0]             \n",
      "                                                                   activation_174[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 6, 6, 768)     0           activation_177[0][0]             \n",
      "                                                                   activation_178[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_179 (Activation)      (None, 6, 6, 192)     0           batch_normalization_179[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)             (None, 6, 6, 2048)    0           activation_171[0][0]             \n",
      "                                                                   mixed9_0[0][0]                   \n",
      "                                                                   concatenate_3[0][0]              \n",
      "                                                                   activation_179[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)              (None, 6, 6, 448)     917504      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchNo (None, 6, 6, 448)     1344        conv2d_184[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_184 (Activation)      (None, 6, 6, 448)     0           batch_normalization_184[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)              (None, 6, 6, 384)     786432      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)              (None, 6, 6, 384)     1548288     activation_184[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchNo (None, 6, 6, 384)     1152        conv2d_181[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchNo (None, 6, 6, 384)     1152        conv2d_185[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_181 (Activation)      (None, 6, 6, 384)     0           batch_normalization_181[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_185 (Activation)      (None, 6, 6, 384)     0           batch_normalization_185[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)              (None, 6, 6, 384)     442368      activation_181[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)              (None, 6, 6, 384)     442368      activation_181[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)              (None, 6, 6, 384)     442368      activation_185[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)              (None, 6, 6, 384)     442368      activation_185[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePoo (None, 6, 6, 2048)    0           mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)              (None, 6, 6, 320)     655360      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchNo (None, 6, 6, 384)     1152        conv2d_182[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchNo (None, 6, 6, 384)     1152        conv2d_183[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchNo (None, 6, 6, 384)     1152        conv2d_186[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchNo (None, 6, 6, 384)     1152        conv2d_187[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)              (None, 6, 6, 192)     393216      average_pooling2d_18[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchNo (None, 6, 6, 320)     960         conv2d_180[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_182 (Activation)      (None, 6, 6, 384)     0           batch_normalization_182[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_183 (Activation)      (None, 6, 6, 384)     0           batch_normalization_183[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_186 (Activation)      (None, 6, 6, 384)     0           batch_normalization_186[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_187 (Activation)      (None, 6, 6, 384)     0           batch_normalization_187[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchNo (None, 6, 6, 192)     576         conv2d_188[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_180 (Activation)      (None, 6, 6, 320)     0           batch_normalization_180[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)           (None, 6, 6, 768)     0           activation_182[0][0]             \n",
      "                                                                   activation_183[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 6, 6, 768)     0           activation_186[0][0]             \n",
      "                                                                   activation_187[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_188 (Activation)      (None, 6, 6, 192)     0           batch_normalization_188[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)            (None, 6, 6, 2048)    0           activation_180[0][0]             \n",
      "                                                                   mixed9_1[0][0]                   \n",
      "                                                                   concatenate_4[0][0]              \n",
      "                                                                   activation_188[0][0]             \n",
      "====================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the VGG16 network\n",
    "base_model = InceptionV3(weights=None, include_top=False, input_shape=(img_height,img_width,3))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(num_classes, activation = 'sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_with_threshold(y_true, y_pred):\n",
    "    threshold = 0.5\n",
    "    y_pred = K.cast(K.greater(y_pred, threshold), K.floatx())\n",
    "    return K.mean(K.equal(y_true, y_pred))\n",
    "\n",
    "def hamming_dist(y_true, y_pred):\n",
    "    threshold = 0.5\n",
    "    y_pred = K.cast(K.greater(y_pred, threshold), K.floatx())\n",
    "    return K.mean(K.sum(K.abs(y_true - y_pred), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Train on 1000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 2029s - loss: 0.9809 - accuracy_with_threshold: 0.8826 - hamming_dist: 1.9960 - val_loss: 0.3580 - val_accuracy_with_threshold: 0.9034 - val_hamming_dist: 1.6415\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=[accuracy_with_threshold, hamming_dist])\n",
    "\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                     validation_data=(x_test, y_test), shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_accuracy_with_threshold': [0.90344117927551271], 'hamming_dist': [1.996], 'val_loss': [0.35803151702880859], 'loss': [0.98093994092941283], 'val_hamming_dist': [1.6415], 'accuracy_with_threshold': [0.88258823204040526]}\n"
     ]
    }
   ],
   "source": [
    "print(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 17)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.903441\n"
     ]
    }
   ],
   "source": [
    "y_pred = K.cast(K.greater(y_pred, 0.5), K.floatx())\n",
    "sess = tf.InteractiveSession()\n",
    "y_pred = y_pred.eval()\n",
    "y_pre = K.mean(K.equal(y_test, y_pred))\n",
    "y_pre = y_pre.eval()\n",
    "print(y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agriculture',\n",
       " 'artisinal_mine',\n",
       " 'bare_ground',\n",
       " 'blooming',\n",
       " 'blow_down',\n",
       " 'clear',\n",
       " 'cloudy',\n",
       " 'conventional_mine',\n",
       " 'cultivation',\n",
       " 'habitation',\n",
       " 'haze',\n",
       " 'partly_cloud',\n",
       " 'primary',\n",
       " 'road',\n",
       " 'selective_logging',\n",
       " 'slash_burn',\n",
       " 'water']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29473,  5907, 15586, 13899, 13543, 24055, 37775,  7774, 32957, 10629])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_a = labels.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_a[29473]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('output/output-indices.txt', 'w') as output:\n",
    "    output.write(\"shaffled index-indices:\" + '\\n')\n",
    "    for line in indices:\n",
    "        output.write(str(line)+'\\n')\n",
    "        \n",
    "with open('output/output-y_train.txt', 'w') as output:\n",
    "    output.write(\"train labels-y_train:\" + '\\n')\n",
    "    for line in y_train:\n",
    "        output.write(str(line)+'\\n')\n",
    "        \n",
    "with open('output/output-y_test.txt', 'w') as output:\n",
    "    output.write(\"train labels-y_test:\" + '\\n')\n",
    "    for line in y_test:\n",
    "        output.write(str(line)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output/output-y_pred.txt', 'w') as output:\n",
    "    output.write(\"predict labels-y_pred:\" + '\\n')\n",
    "    for line in y_pred:\n",
    "        output.write(str(line)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('output/output-indices_test.txt', 'w') as output:\n",
    "    output.write(\"shaffled index-indices_test:\" + '\\n')\n",
    "    for line in indices[:n_test]:\n",
    "        output.write(str(line)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output/output-indices_train.txt', 'w') as output:\n",
    "    output.write(\"shaffled index-indices_train:\" + '\\n')\n",
    "    for line in indices[n_test:n_test+n_train]:\n",
    "        output.write(str(line)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
